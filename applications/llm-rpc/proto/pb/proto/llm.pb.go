// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v3.21.12
// source: proto/llm.proto

package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	_ "google.golang.org/protobuf/types/known/anypb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type LLMProvider int32

const (
	LLMProvider_VOLCENGINE LLMProvider = 0
	LLMProvider_ALIYUN     LLMProvider = 1
	LLMProvider_GLM        LLMProvider = 2 // 智谱
	LLMProvider_COZE       LLMProvider = 3 // 扣子
)

// Enum value maps for LLMProvider.
var (
	LLMProvider_name = map[int32]string{
		0: "VOLCENGINE",
		1: "ALIYUN",
		2: "GLM",
		3: "COZE",
	}
	LLMProvider_value = map[string]int32{
		"VOLCENGINE": 0,
		"ALIYUN":     1,
		"GLM":        2,
		"COZE":       3,
	}
)

func (x LLMProvider) Enum() *LLMProvider {
	p := new(LLMProvider)
	*p = x
	return p
}

func (x LLMProvider) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LLMProvider) Descriptor() protoreflect.EnumDescriptor {
	return file_proto_llm_proto_enumTypes[0].Descriptor()
}

func (LLMProvider) Type() protoreflect.EnumType {
	return &file_proto_llm_proto_enumTypes[0]
}

func (x LLMProvider) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LLMProvider.Descriptor instead.
func (LLMProvider) EnumDescriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{0}
}

type ChatMessageRole int32

const (
	ChatMessageRole_SYSTEM    ChatMessageRole = 0
	ChatMessageRole_USER      ChatMessageRole = 1
	ChatMessageRole_ASSISTANT ChatMessageRole = 2
)

// Enum value maps for ChatMessageRole.
var (
	ChatMessageRole_name = map[int32]string{
		0: "SYSTEM",
		1: "USER",
		2: "ASSISTANT",
	}
	ChatMessageRole_value = map[string]int32{
		"SYSTEM":    0,
		"USER":      1,
		"ASSISTANT": 2,
	}
)

func (x ChatMessageRole) Enum() *ChatMessageRole {
	p := new(ChatMessageRole)
	*p = x
	return p
}

func (x ChatMessageRole) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ChatMessageRole) Descriptor() protoreflect.EnumDescriptor {
	return file_proto_llm_proto_enumTypes[1].Descriptor()
}

func (ChatMessageRole) Type() protoreflect.EnumType {
	return &file_proto_llm_proto_enumTypes[1]
}

func (x ChatMessageRole) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ChatMessageRole.Descriptor instead.
func (ChatMessageRole) EnumDescriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{1}
}

// 聊天请求
type ChatRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Messages      []*ChatMessage         `protobuf:"bytes,1,rep,name=messages,proto3" json:"messages,omitempty"`
	Provider      LLMProvider            `protobuf:"varint,2,opt,name=provider,proto3,enum=llm.LLMProvider" json:"provider,omitempty"` // 平台，范围
	ModelId       string                 `protobuf:"bytes,3,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`          // 模型ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatRequest) Reset() {
	*x = ChatRequest{}
	mi := &file_proto_llm_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatRequest) ProtoMessage() {}

func (x *ChatRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatRequest.ProtoReflect.Descriptor instead.
func (*ChatRequest) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{0}
}

func (x *ChatRequest) GetMessages() []*ChatMessage {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *ChatRequest) GetProvider() LLMProvider {
	if x != nil {
		return x.Provider
	}
	return LLMProvider_VOLCENGINE
}

func (x *ChatRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

// 聊天消息
type ChatMessage struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          ChatMessageRole        `protobuf:"varint,1,opt,name=role,proto3,enum=llm.ChatMessageRole" json:"role,omitempty"` // 角色：system/user/assistant
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`                     // 消息内容
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatMessage) Reset() {
	*x = ChatMessage{}
	mi := &file_proto_llm_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatMessage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatMessage) ProtoMessage() {}

func (x *ChatMessage) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatMessage.ProtoReflect.Descriptor instead.
func (*ChatMessage) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{1}
}

func (x *ChatMessage) GetRole() ChatMessageRole {
	if x != nil {
		return x.Role
	}
	return ChatMessageRole_SYSTEM
}

func (x *ChatMessage) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

// 聊天响应
type ChatResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`           // 回复的消息
	IsEnd         bool                   `protobuf:"varint,3,opt,name=is_end,json=isEnd,proto3" json:"is_end,omitempty"` // 是否结束
	Created       int64                  `protobuf:"varint,4,opt,name=created,proto3" json:"created,omitempty"`          // 创建时间
	Model         string                 `protobuf:"bytes,5,opt,name=model,proto3" json:"model,omitempty"`               // 模型
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatResponse) Reset() {
	*x = ChatResponse{}
	mi := &file_proto_llm_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatResponse) ProtoMessage() {}

func (x *ChatResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatResponse.ProtoReflect.Descriptor instead.
func (*ChatResponse) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{2}
}

func (x *ChatResponse) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ChatResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *ChatResponse) GetIsEnd() bool {
	if x != nil {
		return x.IsEnd
	}
	return false
}

func (x *ChatResponse) GetCreated() int64 {
	if x != nil {
		return x.Created
	}
	return 0
}

func (x *ChatResponse) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

// 获取模型列表请求
type ModelListRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      LLMProvider            `protobuf:"varint,1,opt,name=provider,proto3,enum=llm.LLMProvider" json:"provider,omitempty"` // 平台，范围
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelListRequest) Reset() {
	*x = ModelListRequest{}
	mi := &file_proto_llm_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelListRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelListRequest) ProtoMessage() {}

func (x *ModelListRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelListRequest.ProtoReflect.Descriptor instead.
func (*ModelListRequest) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{3}
}

func (x *ModelListRequest) GetProvider() LLMProvider {
	if x != nil {
		return x.Provider
	}
	return LLMProvider_VOLCENGINE
}

// 获取模型列表响应
type ModelListResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []string               `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"` // 模型列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelListResponse) Reset() {
	*x = ModelListResponse{}
	mi := &file_proto_llm_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelListResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelListResponse) ProtoMessage() {}

func (x *ModelListResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelListResponse.ProtoReflect.Descriptor instead.
func (*ModelListResponse) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{4}
}

func (x *ModelListResponse) GetModels() []string {
	if x != nil {
		return x.Models
	}
	return nil
}

type IndentRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      LLMProvider            `protobuf:"varint,1,opt,name=provider,proto3,enum=llm.LLMProvider" json:"provider,omitempty"`
	Messages      []*ChatMessage         `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	ModelId       string                 `protobuf:"bytes,3,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"` // 模型ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *IndentRequest) Reset() {
	*x = IndentRequest{}
	mi := &file_proto_llm_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *IndentRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*IndentRequest) ProtoMessage() {}

func (x *IndentRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use IndentRequest.ProtoReflect.Descriptor instead.
func (*IndentRequest) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{5}
}

func (x *IndentRequest) GetProvider() LLMProvider {
	if x != nil {
		return x.Provider
	}
	return LLMProvider_VOLCENGINE
}

func (x *IndentRequest) GetMessages() []*ChatMessage {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *IndentRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

type FunctionCall struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Arguments     string                 `protobuf:"bytes,2,opt,name=arguments,proto3" json:"arguments,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FunctionCall) Reset() {
	*x = FunctionCall{}
	mi := &file_proto_llm_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FunctionCall) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FunctionCall) ProtoMessage() {}

func (x *FunctionCall) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FunctionCall.ProtoReflect.Descriptor instead.
func (*FunctionCall) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{6}
}

func (x *FunctionCall) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *FunctionCall) GetArguments() string {
	if x != nil {
		return x.Arguments
	}
	return ""
}

type IndentResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Nlu           string                 `protobuf:"bytes,1,opt,name=nlu,proto3" json:"nlu,omitempty"`
	FunctionCall  *FunctionCall          `protobuf:"bytes,2,opt,name=function_call,json=functionCall,proto3" json:"function_call,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *IndentResponse) Reset() {
	*x = IndentResponse{}
	mi := &file_proto_llm_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *IndentResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*IndentResponse) ProtoMessage() {}

func (x *IndentResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_llm_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use IndentResponse.ProtoReflect.Descriptor instead.
func (*IndentResponse) Descriptor() ([]byte, []int) {
	return file_proto_llm_proto_rawDescGZIP(), []int{7}
}

func (x *IndentResponse) GetNlu() string {
	if x != nil {
		return x.Nlu
	}
	return ""
}

func (x *IndentResponse) GetFunctionCall() *FunctionCall {
	if x != nil {
		return x.FunctionCall
	}
	return nil
}

var File_proto_llm_proto protoreflect.FileDescriptor

const file_proto_llm_proto_rawDesc = "" +
	"\n" +
	"\x0fproto/llm.proto\x12\x03llm\x1a\x19google/protobuf/any.proto\"\x84\x01\n" +
	"\vChatRequest\x12,\n" +
	"\bmessages\x18\x01 \x03(\v2\x10.llm.ChatMessageR\bmessages\x12,\n" +
	"\bprovider\x18\x02 \x01(\x0e2\x10.llm.LLMProviderR\bprovider\x12\x19\n" +
	"\bmodel_id\x18\x03 \x01(\tR\amodelId\"Q\n" +
	"\vChatMessage\x12(\n" +
	"\x04role\x18\x01 \x01(\x0e2\x14.llm.ChatMessageRoleR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\"\x7f\n" +
	"\fChatResponse\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x12\x15\n" +
	"\x06is_end\x18\x03 \x01(\bR\x05isEnd\x12\x18\n" +
	"\acreated\x18\x04 \x01(\x03R\acreated\x12\x14\n" +
	"\x05model\x18\x05 \x01(\tR\x05model\"@\n" +
	"\x10ModelListRequest\x12,\n" +
	"\bprovider\x18\x01 \x01(\x0e2\x10.llm.LLMProviderR\bprovider\"+\n" +
	"\x11ModelListResponse\x12\x16\n" +
	"\x06models\x18\x01 \x03(\tR\x06models\"\x86\x01\n" +
	"\rIndentRequest\x12,\n" +
	"\bprovider\x18\x01 \x01(\x0e2\x10.llm.LLMProviderR\bprovider\x12,\n" +
	"\bmessages\x18\x02 \x03(\v2\x10.llm.ChatMessageR\bmessages\x12\x19\n" +
	"\bmodel_id\x18\x03 \x01(\tR\amodelId\"@\n" +
	"\fFunctionCall\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1c\n" +
	"\targuments\x18\x02 \x01(\tR\targuments\"Z\n" +
	"\x0eIndentResponse\x12\x10\n" +
	"\x03nlu\x18\x01 \x01(\tR\x03nlu\x126\n" +
	"\rfunction_call\x18\x02 \x01(\v2\x11.llm.FunctionCallR\ffunctionCall*<\n" +
	"\vLLMProvider\x12\x0e\n" +
	"\n" +
	"VOLCENGINE\x10\x00\x12\n" +
	"\n" +
	"\x06ALIYUN\x10\x01\x12\a\n" +
	"\x03GLM\x10\x02\x12\b\n" +
	"\x04COZE\x10\x03*6\n" +
	"\x0fChatMessageRole\x12\n" +
	"\n" +
	"\x06SYSTEM\x10\x00\x12\b\n" +
	"\x04USER\x10\x01\x12\r\n" +
	"\tASSISTANT\x10\x022\xbc\x01\n" +
	"\n" +
	"LLMService\x125\n" +
	"\n" +
	"ChatStream\x12\x10.llm.ChatRequest\x1a\x11.llm.ChatResponse\"\x000\x01\x129\n" +
	"\fIndentDetect\x12\x12.llm.IndentRequest\x1a\x13.llm.IndentResponse\"\x00\x12<\n" +
	"\tModelList\x12\x15.llm.ModelListRequest\x1a\x16.llm.ModelListResponse\"\x00B:Z8github.com/mathiasXie/gin-web/applications/llm-rpc/protob\x06proto3"

var (
	file_proto_llm_proto_rawDescOnce sync.Once
	file_proto_llm_proto_rawDescData []byte
)

func file_proto_llm_proto_rawDescGZIP() []byte {
	file_proto_llm_proto_rawDescOnce.Do(func() {
		file_proto_llm_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_proto_llm_proto_rawDesc), len(file_proto_llm_proto_rawDesc)))
	})
	return file_proto_llm_proto_rawDescData
}

var file_proto_llm_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_proto_llm_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_proto_llm_proto_goTypes = []any{
	(LLMProvider)(0),          // 0: llm.LLMProvider
	(ChatMessageRole)(0),      // 1: llm.ChatMessageRole
	(*ChatRequest)(nil),       // 2: llm.ChatRequest
	(*ChatMessage)(nil),       // 3: llm.ChatMessage
	(*ChatResponse)(nil),      // 4: llm.ChatResponse
	(*ModelListRequest)(nil),  // 5: llm.ModelListRequest
	(*ModelListResponse)(nil), // 6: llm.ModelListResponse
	(*IndentRequest)(nil),     // 7: llm.IndentRequest
	(*FunctionCall)(nil),      // 8: llm.FunctionCall
	(*IndentResponse)(nil),    // 9: llm.IndentResponse
}
var file_proto_llm_proto_depIdxs = []int32{
	3,  // 0: llm.ChatRequest.messages:type_name -> llm.ChatMessage
	0,  // 1: llm.ChatRequest.provider:type_name -> llm.LLMProvider
	1,  // 2: llm.ChatMessage.role:type_name -> llm.ChatMessageRole
	0,  // 3: llm.ModelListRequest.provider:type_name -> llm.LLMProvider
	0,  // 4: llm.IndentRequest.provider:type_name -> llm.LLMProvider
	3,  // 5: llm.IndentRequest.messages:type_name -> llm.ChatMessage
	8,  // 6: llm.IndentResponse.function_call:type_name -> llm.FunctionCall
	2,  // 7: llm.LLMService.ChatStream:input_type -> llm.ChatRequest
	7,  // 8: llm.LLMService.IndentDetect:input_type -> llm.IndentRequest
	5,  // 9: llm.LLMService.ModelList:input_type -> llm.ModelListRequest
	4,  // 10: llm.LLMService.ChatStream:output_type -> llm.ChatResponse
	9,  // 11: llm.LLMService.IndentDetect:output_type -> llm.IndentResponse
	6,  // 12: llm.LLMService.ModelList:output_type -> llm.ModelListResponse
	10, // [10:13] is the sub-list for method output_type
	7,  // [7:10] is the sub-list for method input_type
	7,  // [7:7] is the sub-list for extension type_name
	7,  // [7:7] is the sub-list for extension extendee
	0,  // [0:7] is the sub-list for field type_name
}

func init() { file_proto_llm_proto_init() }
func file_proto_llm_proto_init() {
	if File_proto_llm_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_proto_llm_proto_rawDesc), len(file_proto_llm_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_proto_llm_proto_goTypes,
		DependencyIndexes: file_proto_llm_proto_depIdxs,
		EnumInfos:         file_proto_llm_proto_enumTypes,
		MessageInfos:      file_proto_llm_proto_msgTypes,
	}.Build()
	File_proto_llm_proto = out.File
	file_proto_llm_proto_goTypes = nil
	file_proto_llm_proto_depIdxs = nil
}
